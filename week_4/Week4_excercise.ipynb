{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rpzXl6gplIv1",
        "DtYEfs_tmKab",
        "Xhb-wZwWrp_x",
        "rLdfCgswV3M_"
      ],
      "authorship_tag": "ABX9TyOo89K9Rj+SAlDIINHau0N2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StarPrecursor/Adv_Python_Practice/blob/main/week_4/Week4_excercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 4 Excercise\n",
        "Train a simple (single layer, single fully connected layer, etc.) neural network through JAX vectorization (maybe you can try vectorization techniques in PyTorch and Tensorflow respectively). Compare their performance with each and with the results derived in Week 3â€™s exercise."
      ],
      "metadata": {
        "id": "jjikpGZFjQWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Settings"
      ],
      "metadata": {
        "id": "f1aDSqjtj7hM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from jax import random\n",
        "\n",
        "seed = 42\n",
        "seed_prng = random.PRNGKey(seed)\n",
        "\n",
        "n_layers = 3\n",
        "n_nodes = 100\n",
        "init_scale = 0.05\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size = 128\n",
        "learn_rate = 0.0001"
      ],
      "metadata": {
        "id": "3RDjE1y1j-Eg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "HreQOZtWj2_9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "q-qJz8fUjIZ1"
      },
      "outputs": [],
      "source": [
        "# from sklearn.datasets import load_breast_cancer\n",
        "# \n",
        "# data = load_breast_cancer()\n",
        "# X = data.data.transpose()\n",
        "# y = data.target\n",
        "# \n",
        "# print(type(X), X.shape)\n",
        "# print(type(y), y.shape)\n",
        "# print(data.feature_names)\n",
        "# print(data.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(\n",
        "  n_samples=5000, n_features=50, centers=2, cluster_std=25, random_state=0\n",
        ")\n",
        "X = X.transpose()\n",
        "y = y.transpose()"
      ],
      "metadata": {
        "id": "_cR3666rRvi7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jax implementation"
      ],
      "metadata": {
        "id": "rpzXl6gplIv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random"
      ],
      "metadata": {
        "id": "yNjmbMfgmSEz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build components"
      ],
      "metadata": {
        "id": "DtYEfs_tmKab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lin(params, x):\n",
        "  return jnp.dot(params[0], x) + params[1]\n",
        "\n",
        "def relu(x):\n",
        "  return jnp.maximum(0, x)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 0.5 * (jnp.tanh(x / 2) + 1)\n",
        "\n",
        "def loss(params, y_pred, y_true):\n",
        "  label_probs = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
        "  return -jnp.sum(jnp.log(label_probs))\n"
      ],
      "metadata": {
        "id": "xa3umb11lDCo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "Xhb-wZwWrp_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params_list, x):\n",
        "  cur = x\n",
        "  # hidden\n",
        "  for params in params_list[:-1]:\n",
        "    cur = relu(lin(params, cur))\n",
        "  # output\n",
        "  params = params_list[-1]\n",
        "\n",
        "  return sigmoid(lin(params, cur))\n",
        "\n",
        "def batch_predict(params_list, x):\n",
        "  # vmap vectorize\n",
        "  return vmap(predict, in_axes=(None, 1))(params_list, x)\n",
        "\n",
        "def loss(params_list, x, y):\n",
        "  preds = predict(params_list, x)\n",
        "  label_probs = preds * y + (1 - preds) * (1 - y)\n",
        "  # jnp.sum vectorize\n",
        "  return -jnp.sum(jnp.log(label_probs))\n",
        "\n",
        "loss_jit = jit(grad(loss))\n",
        "\n",
        "def update(params_list, x, y):\n",
        "  grads = loss_jit(params_list, x, y)\n",
        "  new_params_list = []\n",
        "  for (w, b), (dw, db) in zip(params_list, grads):\n",
        "    new_params_list.append(\n",
        "      (w - learn_rate * dw, b - learn_rate * db)\n",
        "    )\n",
        "  return new_params_list"
      ],
      "metadata": {
        "id": "BnNCshNN_UUw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "DmDWRC4AqNJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JAX_Model:\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    self.dims = [input_dim] + [n_nodes] * n_layers + [1]\n",
        "    self.params_list = []\n",
        "\n",
        "  def init_params(self):\n",
        "    seed_list = random.split(seed_prng, len(self.dims) - 1)\n",
        "    for i in range(len(self.dims) - 1):\n",
        "      w_seed, b_seed = random.split(seed_list[i])\n",
        "      dim_in = self.dims[i]\n",
        "      dim_out = self.dims[i+1]\n",
        "      w = init_scale * random.normal(w_seed, (dim_out, dim_in))\n",
        "      b = init_scale * random.normal(b_seed, (dim_out, 1))\n",
        "      self.params_list.append((w, b))\n",
        "\n",
        "  def train(self, x, y):\n",
        "    for epoch in range(n_epochs):\n",
        "      self.params_list = update(self.params_list, x, y)\n",
        "      cur_loss = loss(self.params_list, x, y)\n",
        "      print(f\"epoch={epoch}, loss={cur_loss}\")\n",
        "  \n",
        "  def predict(self, x):\n",
        "    return predict(self.params_list, x)\n",
        "\n",
        "  def batch_predict(self, x):\n",
        "    return batch_predict(self.params_list, x)\n"
      ],
      "metadata": {
        "id": "Y15_JD6HqN6k"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax_mod = JAX_Model(X.shape[0])\n",
        "jax_mod.init_params()\n",
        "y_init = jax_mod.predict(X)\n",
        "print(y_init.shape)\n",
        "#print(y_init)\n",
        "cur_loss = loss(jax_mod.params_list, X, y)\n",
        "print(cur_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7w3AVTt4bIX",
        "outputId": "f1594727-04ae-4387-ed2f-803d8ac44457"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5000)\n",
            "3709.6646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "jax_mod.train(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF_LsSP9-V4n",
        "outputId": "a06c0e37-3798-4f8e-995f-d0b6c0bdb91f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0, loss=6534.31494140625\n",
            "epoch=1, loss=9767.412109375\n",
            "epoch=2, loss=3760.5927734375\n",
            "epoch=3, loss=3072.244873046875\n",
            "epoch=4, loss=2404.154296875\n",
            "epoch=5, loss=8105.107421875\n",
            "epoch=6, loss=2960.2490234375\n",
            "epoch=7, loss=1782.263427734375\n",
            "epoch=8, loss=2220.838623046875\n",
            "epoch=9, loss=2514.513671875\n",
            "epoch=10, loss=1711.5341796875\n",
            "epoch=11, loss=1349.20068359375\n",
            "epoch=12, loss=1298.455322265625\n",
            "epoch=13, loss=1274.458251953125\n",
            "epoch=14, loss=1255.9686279296875\n",
            "epoch=15, loss=1239.9541015625\n",
            "epoch=16, loss=1225.56005859375\n",
            "epoch=17, loss=1212.0341796875\n",
            "epoch=18, loss=1199.35546875\n",
            "epoch=19, loss=1187.437255859375\n",
            "CPU times: user 1.5 s, sys: 80.7 ms, total: 1.58 s\n",
            "Wall time: 1.07 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Comparing with Tensorflow and PyTorch\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oLVIIRr5DEu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow implementation"
      ],
      "metadata": {
        "id": "rLdfCgswV3M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "OwDNK4m8V44P"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk4toXh1XQMQ",
        "outputId": "522423a8-560d-4e27-d5ca-78c0f679df0a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 5000) (5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[0]\n",
        "X_t = X.transpose()\n",
        "\n",
        "tf_mod = tf.keras.Sequential()\n",
        "tf_mod.add(tf.keras.layers.Dense(n_nodes, input_shape=(input_dim,)))\n",
        "for i in range(n_layers):\n",
        "  tf_mod.add(tf.keras.layers.Dense(n_nodes))\n",
        "tf_mod.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "tf_mod.compile(optimizer=opt, loss=\"BinaryCrossentropy\")"
      ],
      "metadata": {
        "id": "50_GGr24WLsD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tf_mod.fit(X_t, y, batch_size=batch_size, epochs=n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaSJHo6lY8OF",
        "outputId": "0d0a8c4e-d797-47d2-a163-6a2291a39118"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 1s 2ms/step - loss: 4.2725\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 3.5303\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 3.4446\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 3.2740\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 3.0056\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.3702\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9527\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9527\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9527\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 5.9527\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 5.9527\n",
            "CPU times: user 3.1 s, sys: 117 ms, total: 3.21 s\n",
            "Wall time: 2.62 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55cfa2dbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZs7qwXtYm-o"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch implementation"
      ],
      "metadata": {
        "id": "drT8kk3LZPrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "JMQ20_TTZTOO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X.shape[0]\n",
        "X_t = X.transpose()"
      ],
      "metadata": {
        "id": "wEL6TJO-ZjgC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = []\n",
        "layers.append(nn.Linear(input_dim, n_nodes))\n",
        "layers.append(nn.ReLU())\n",
        "for i in range(n_layers):\n",
        "  layers.append(nn.Linear(n_nodes, n_nodes))\n",
        "  layers.append(nn.ReLU())\n",
        "layers.append(nn.Linear(n_nodes, 1))\n",
        "layers.append(nn.Sigmoid())\n",
        "\n",
        "model = nn.Sequential(*layers)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy38LJ85ZWC6",
        "outputId": "beee95eb-c1ff-49ee-92d4-f933f39292c9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=50, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): Linear(in_features=100, out_features=1, bias=True)\n",
            "  (9): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_x = torch.from_numpy(X_t).float()\n",
        "data_y = torch.from_numpy(y.reshape(-1,1)).float()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)"
      ],
      "metadata": {
        "id": "5zXfGYXhayY9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(n_epochs):\n",
        "  pred_y = model(data_x).float()\n",
        "  loss = loss_function(pred_y, data_y)\n",
        "  model.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dYk9OElafcc",
        "outputId": "98958548-58ea-4e3b-98d5-169f271e6714"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 593 ms, sys: 20.9 ms, total: 614 ms\n",
            "Wall time: 612 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6_pJwlcdNp4"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}